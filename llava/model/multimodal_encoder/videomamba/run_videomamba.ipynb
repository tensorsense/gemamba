{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.append(Path(\"videomamba/video_mm\").resolve().as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup configuration\n",
    "# from videomamba.video_mm.exp_zs.msrvtt.config\n",
    "\n",
    "from videomamba.video_mm.models.umt_videomamba import UMT_VIDEOMAMBA\n",
    "from videomamba.video_mm.utils.easydict import EasyDict\n",
    "\n",
    "num_frames = 8\n",
    "img_size = 224\n",
    "batch_size = 64\n",
    "max_txt_l = 32\n",
    "\n",
    "# model_pth = \"videomamba_m16_k400_mask_pt_f8_res224.pth\"  # default in all configs\n",
    "# model_pth = \"videomamba_m16_5M_f8_res224.pth\"  # broken pos\n",
    "model_pth = \"videomamba_m16_k400_mask_ft_f8_res224.pth\"\n",
    "\n",
    "config_dict = {\n",
    "    \"num_frames\": num_frames,\n",
    "    \"num_frames_test\": num_frames,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"max_txt_l\": max_txt_l,\n",
    "    \"inputs\": {\n",
    "        \"image_res\": img_size,\n",
    "        \"video_input\": {\n",
    "            \"num_frames\": num_frames,\n",
    "            \"sample_type\": \"rand\",\n",
    "            \"num_frames_test\": num_frames,\n",
    "            \"sample_type_test\": \"middle\",\n",
    "            \"random_aug\": False\n",
    "        },\n",
    "        \"max_txt_l\": {\n",
    "            \"image\": max_txt_l,\n",
    "            \"video\": max_txt_l\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            \"image\": batch_size,\n",
    "            \"video\": batch_size\n",
    "        },\n",
    "        \"batch_size_test\": {\n",
    "            \"image\": batch_size,\n",
    "            \"video\": batch_size\n",
    "        }\n",
    "    },\n",
    "    \"text_enc\": \"bert\",\n",
    "    \"model\": {\n",
    "        \"model_cls\": UMT_VIDEOMAMBA,\n",
    "        \"vision_encoder\": {\n",
    "            \"name\": \"videomamba_middle\",\n",
    "            \"img_size\": img_size,\n",
    "            \"patch_size\": 16,\n",
    "            \"depth\": 32,\n",
    "            \"embed_dim\": 576,\n",
    "            \"drop_path_rate\": 0.25,\n",
    "            \"ssm_cfg\": None,\n",
    "            \"norm_epsilon\": 1e-5,\n",
    "            \"fused_add_norm\": True,\n",
    "            \"rms_norm\": True,\n",
    "            \"residual_in_fp32\": True,\n",
    "            \"bimamba\": True,\n",
    "            \"pool_type\": \"cls+avg\",\n",
    "            \"kernel_size\": 1,\n",
    "            \"num_frames\": num_frames,\n",
    "            \"ckpt_num_frame\": 8,\n",
    "            \"use_checkpoint\": False,\n",
    "            \"checkpoint_num\": 0,\n",
    "            \"clip_decoder_embed_dim\": 576,\n",
    "            \"clip_output_dim\": 512,\n",
    "            \"clip_norm_type\": \"l2\",\n",
    "            \"clip_return_layer\": 1,\n",
    "            \"clip_student_return_interval\": 1,\n",
    "            \"pretrained\": model_pth,\n",
    "            \"clip_teacher\": \"none\",\n",
    "            \"clip_img_size\": img_size,\n",
    "            \"clip_return_interval\": 1,\n",
    "            \"video_mask_type\": \"none\",\n",
    "            \"video_mask_ratio\": 0.0,\n",
    "            \"video_double_mask_ratio\": 0.0,\n",
    "            \"image_mask_type\": \"none\",\n",
    "            \"image_mask_ratio\": 0.0,\n",
    "            \"image_double_mask_ratio\": 0.0,\n",
    "            \"keep_temporal\": True\n",
    "        },\n",
    "        \"text_encoder\": {\n",
    "            \"name\": \"bert_base\",\n",
    "            \"pretrained\": \"bert-base-uncased\",\n",
    "            \"config\": \"videomamba/video_mm/configs/config_bert.json\",\n",
    "            \"d_model\": 768,\n",
    "            \"fusion_layer\": 9\n",
    "        },\n",
    "        \"multimodal\": {\"enable\": True},\n",
    "        \"embed_dim\": 512,\n",
    "        \"temp\": 0.07\n",
    "    },\n",
    "    \"criterion\": {\n",
    "        \"loss_weight\": {\n",
    "            \"vtc\": 1.0,\n",
    "            \"mlm\": 1.0,\n",
    "            \"vtm\": 1.0,\n",
    "            \"uta\": 0.0\n",
    "        },\n",
    "        \"vtm_hard_neg\": True,\n",
    "        \"mlm_masking_prob\": 0.5,\n",
    "        \"uta_norm_type\": \"l2\",\n",
    "        \"uta_loss_type\": \"l2\"\n",
    "    },\n",
    "    \"optimizer\": {\n",
    "        \"opt\": \"adamW\",\n",
    "        \"lr\": 1e-5,\n",
    "        \"opt_betas\": [0.9, 0.999],\n",
    "        \"weight_decay\": 0.02,\n",
    "        \"max_grad_norm\": -1,\n",
    "        \"different_lr\": {\"enable\": False, \"module_names\": [], \"lr\": 4e-3}\n",
    "    },\n",
    "    \"scheduler\": {\n",
    "        \"sched\": \"cosine\",\n",
    "        \"epochs\": 2,\n",
    "        \"min_lr_multi\": 0.01,\n",
    "        \"warmup_epochs\": 0.2,\n",
    "        \"num_warmup_steps\": 8,\n",
    "        \"num_training_steps\": 1000,\n",
    "    },\n",
    "    \"evaluate\": False,\n",
    "    \"deep_fusion\": False,\n",
    "    \"evaluation\": {\n",
    "        \"eval_frame_ensemble\": \"concat\",\n",
    "        \"eval_x_only\": False,\n",
    "        \"k_test\": 128,\n",
    "        \"eval_offload\": False\n",
    "    },\n",
    "    \"fp16\": True,\n",
    "    \"bf16\": True,\n",
    "    \"gradient_checkpointing\": True,\n",
    "    \"device\": \"cuda\",\n",
    "    \"mode\": \"pt\",\n",
    "    \"output_dir\": None,\n",
    "    \"resume\": False,\n",
    "    \"debug\": False,\n",
    "    \"log_freq\": 1,\n",
    "    \"seed\": 42,\n",
    "    \"zero_shot\": True,\n",
    "    \"save_latest\": False,\n",
    "    \"auto_resume\": False,\n",
    "    \"pretrained_path\": model_pth,\n",
    "    \"distributed\": False,\n",
    "}\n",
    "\n",
    "config = EasyDict(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/OpenGVLab/VideoMamba/resolve/main/videomamba_m16_k400_mask_pt_f8_res224.pth\n",
    "# !wget https://huggingface.co/OpenGVLab/VideoMamba/resolve/main/videomamba_m16_5M_f8_res224.pth\n",
    "!wget https://huggingface.co/OpenGVLab/VideoMamba/resolve/main/videomamba_m16_k400_mask_ft_f8_res224.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "# from videomamba.video_mm.tasks.retrieval\n",
    "\n",
    "from tasks.shared_utils import setup_model\n",
    "\n",
    "(\n",
    "    model,\n",
    "    model_without_ddp,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    scaler,\n",
    "    tokenizer,\n",
    "    start_epoch,\n",
    "    global_step,\n",
    ") = setup_model(\n",
    "    config,\n",
    "    model_cls=config.model.model_cls,\n",
    "    has_decoder=False,\n",
    "    pretrain=False,\n",
    "    # find_unused_parameters=True,\n",
    "    find_unused_parameters=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess video\n",
    "# from videomamba.video_mm.dataset.__init__ -> create_dataset()\n",
    "# from videomamba.video_mm.dataset.base_dataset -> ImageVideoBaseDataset.load_and_transform_media_data_video()\n",
    "\n",
    "from torchvision import transforms\n",
    "from videomamba.video_mm.dataset.video_utils import read_frames_decord\n",
    "\n",
    "mean = (0.48145466, 0.4578275, 0.40821073)\n",
    "std = (0.26862954, 0.26130258, 0.27577711)\n",
    "\n",
    "normalize = transforms.Normalize(mean, std)\n",
    "\n",
    "# loaded images and videos are torch.Tensor of torch.uint8 format,\n",
    "# ordered as (T, 1 or 3, H, W) where T=1 for image\n",
    "type_transform = transforms.Lambda(lambda x: x.float().div(255.0))\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(\n",
    "            (config.inputs.image_res, config.inputs.image_res),\n",
    "            interpolation=transforms.InterpolationMode.BICUBIC,\n",
    "        ),\n",
    "        type_transform,\n",
    "        normalize,\n",
    "    ]\n",
    ")\n",
    "\n",
    "video_reader = read_frames_decord\n",
    "\n",
    "max_num_frames = -1\n",
    "frames, frame_indices, video_duration = video_reader(\n",
    "    \"/data/vlm_sandbox/videos/lie1.mp4\",\n",
    "    config.inputs.video_input.num_frames,\n",
    "    config.inputs.video_input.sample_type,\n",
    "    max_num_frames=max_num_frames,\n",
    "    client=None,\n",
    "    trimmed30=False,\n",
    ")\n",
    "\n",
    "frames = transform(frames).unsqueeze(0)\n",
    "frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode image\n",
    "# from videomamba.video_mm.tasks.retrieval_utils -> extract_vision_feats()\n",
    "\n",
    "import torch\n",
    "from einops import rearrange\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "image_feats_all = []\n",
    "pooled_image_feats_all = []\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "    image = frames.to(device, non_blocking=True)\n",
    "    image_feat, pooled_image_feat = model.encode_vision(image, test=True)\n",
    "\n",
    "if len(image_feat.shape) == 4:\n",
    "    image_feat = rearrange(image_feat, \"b t l c -> b (t l) c\").contiguous()\n",
    "image_feat = image_feat.unsqueeze(1)  # (bsz, 1, #frm*L, d)\n",
    "\n",
    "if config.evaluation.eval_offload:\n",
    "    image_feats_all.append(image_feat.cpu())\n",
    "    pooled_image_feats_all.append(pooled_image_feat.cpu())\n",
    "else:\n",
    "    image_feats_all.append(image_feat)\n",
    "    pooled_image_feats_all.append(pooled_image_feat)\n",
    "\n",
    "image_feats_all = torch.cat(image_feats_all, dim=0)\n",
    "pooled_image_feats_all = torch.cat(pooled_image_feats_all, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode text\n",
    "# from videomamba.video_mm.tasks.retrieval_utils -> extract_text_feats()\n",
    "\n",
    "text = \"Person behind a table\"\n",
    "text_bs = 256\n",
    "text_feats = []\n",
    "text_atts = []\n",
    "\n",
    "text_input = tokenizer(\n",
    "    text,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=max_txt_l,\n",
    "    return_tensors=\"pt\",\n",
    ").to(device)\n",
    "\n",
    "text_feat = model.encode_text(text_input)[0]\n",
    "text_feats.append(text_feat)\n",
    "text_atts.append(text_input.attention_mask)\n",
    "\n",
    "text_feats = torch.cat(text_feats, dim=0)\n",
    "text_atts = torch.cat(text_atts, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_feats_all.shape)\n",
    "print(pooled_image_feats_all.shape)\n",
    "print(text_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate similarity\n",
    "# from videomamba.video_mm.tasks.retrieval_utils -> evaluation()\n",
    "\n",
    "from videomamba.video_mm.models.criterions import get_sim\n",
    "\n",
    "_pooled_image_feats = (\n",
    "    pooled_image_feats_all.to(device, non_blocking=True)\n",
    "    if config.evaluation.eval_offload\n",
    "    else pooled_image_feats_all\n",
    ")\n",
    "with torch.cuda.amp.autocast():\n",
    "    i2t_scores, t2i_scores = get_sim(\n",
    "        model.vision_proj(_pooled_image_feats), model.text_proj(text_feats[:, 0])\n",
    "    )\n",
    "\n",
    "print(float(i2t_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
